/*******************************************************************
 * CLASS: HeatmapDataGenerator
 *
 * This class is the driver for the heat map data generation process. 
 * import data matrix files are read in and clustered.  Data tiles, 
 * containing binary data representation of the matrix data are 
 * written out.  Finally, tile structure and column header json 
 * files are generated by the process.
 * 
 * Author: Mark Stucky
 * Date: December 14, 2015
 ******************************************************************/

package mda.ngchm.datagenerator;

import java.io.BufferedReader;
import java.io.DataOutputStream;
import java.io.File;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.nio.ByteBuffer;
import java.util.Arrays;
import java.util.Date;
import java.util.List;
import java.util.ArrayList;
import java.io.OutputStreamWriter;

import mda.ngchm.datagenerator.ImportData;
import static mda.ngchm.datagenerator.ImportConstants.*;


public class HeatmapDataGenerator {

	public static void main(String[] args) {
		System.out.println("START: " + new Date());
		// Extract number of rows and columns from incoming matrix
		int[] rowCols = getInputFileRowCols(args);
		// Create ImportData object for data matrix.  This object will 
		// contain subordinate objects for import layers and import tiles
		ImportData iData =  new ImportData(args, rowCols);
		int summaryInterval = 0;
		// Loop thru ImportData object processing for each ImportDataLayer
		for (int i=0; i < iData.importLayers.size(); i++) {
			ImportLayerData ilData = iData.importLayers.get(i);
			if (ilData.layer.equals(LAYER_SUMMARY)) {
				summaryInterval = ilData.rowInterval;
			}
			// Within each ImportDataLayer, loop thru each of its 
			// ImportTileData objects writing out a tile for each
			for (int j=0; j < ilData.importTiles.size(); j++){
				ImportTileData itData = ilData.importTiles.get(j);
				writeTileFile(iData, ilData, itData);
			}
		}
		// Generate tileStructure.json file for data import
		writeTileStructFile(iData);
		// Generate import row and column label .json files for the import
		writeLabelsFiles(iData.importDir + ROW_LABELS_FILE, iData, true);
		writeLabelsFiles(iData.importDir + COL_LABELS_FILE, iData, false);
		writeDendrogramFile(iData, summaryInterval);
		writeClassificationsFile(iData, summaryInterval);
		if (DEBUG) {
			writeClusteredDebugFile(iData);
		}
		System.out.println("END: " + new Date());  
	}

	/*******************************************************************
	 * METHOD: writeTileFile
	 *
	 * This method writes out individual data tile files by iterating 
	 * thru the data matrix string array, stored on the ImportData object,
	 * and writing out individual binary float values using the ImportLayerData 
	 * and ImportTileData objects as a guideline.
	 ******************************************************************/
	private static void writeTileFile(ImportData iData, ImportLayerData ilData, ImportTileData itData) {
		int writes = 0;
	    try {
	    	//If tile destination dir does not exist, create directory.
	    	File dataDir = new File(iData.importDir+File.separator+ilData.layer);
	    	if (!dataDir.exists()) {
	    		dataDir.mkdirs();
	    	}
			DataOutputStream write = new DataOutputStream(new FileOutputStream(iData.importDir + itData.fileName));
			int rowStart = itData.rowStartPos, rowEnd = itData.rowEndPos;
			int colStart = itData.colStartPos, colEnd = itData.colEndPos; 
			int rowInterval = ilData.rowInterval, colInterval = ilData.colInterval;
			int nextColWrite = 0;
			String[][] matrixArray = iData.reorgMatrix;
			int nextRowWrite = getNextRowWrite(ilData, rowStart);
			int nextCol = getNextColWrite(ilData, colStart);
			DataOutputStream writeRow=null;
			if (DEBUG) { writeRow = new DataOutputStream(new FileOutputStream(iData.importDir  + itData.fileName + TXT_FILE));  }//For debugging: writes out file
			for (int row = rowStart; row < rowEnd; row++) {
				if (row == nextRowWrite) {
					nextColWrite = nextCol;
					String valprint = null;
					if (DEBUG) { valprint = Integer.toString(row); } //For debugging: writes out file
					for (int col = colStart; col < colEnd; col++) {
						if (col == nextColWrite) {
							if (isNumeric(matrixArray[row][col])) {
								float v = Float.parseFloat(matrixArray[row][col]);
								byte f[] = ByteBuffer.allocate(4).putFloat(v).array();
								if (DEBUG) { valprint = valprint + TAB + matrixArray[row][col]; } //For debugging: writes out file
								write.write(f, 3, 1);
								write.write(f, 2, 1);
								write.write(f, 1, 1);
								write.write(f, 0, 1); 
								writes++;
								nextColWrite += colInterval;
							}
						}
					}
					if (DEBUG) { 
						valprint = valprint + "\r\n";  //For debugging: writes out file
						writeRow.writeChars(valprint); 
					} 
					nextRowWrite += rowInterval;
				} 
			}
	    	if (DEBUG) { writeRow.close(); } //For debugging: writes out file
	    	System.out.println("     File " + itData.fileName + " writes: " + writes) ;
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    }
	}

	/*******************************************************************
	 * METHOD: isNumeric
	 *
	 * A helper method evaluating a matrix data element to ensure that 
	 * it contains a numeric value.
	 ******************************************************************/
	public static boolean isNumeric(String str)  
	{  
	  try  {  
	    double d = Double.parseDouble(str);  
	  }   catch(Exception e)  {  
	    return false;  
	  }  
	  return true;  
	}

	/*******************************************************************
	 * METHOD: getNextRowWrite
	 *
	 * A helper method calculating the next row to write when beginning
	 * a new tile.  This is only used when an interval is being used
	 * for thumbnail, summary, and ribbon horizontal layer views.
	 ******************************************************************/
	private static int getNextRowWrite(ImportLayerData ilData, int rowStart) {	
		int nextRowWrite = rowStart;
		if (Arrays.asList(LAYER_THUMBNAIL, LAYER_SUMMARY, LAYER_RIBBONHORIZ).contains(ilData.layer)) {
			if ((rowStart != 1) && (ilData.colInterval != 1)) {
				nextRowWrite = (((rowStart/ilData.rowInterval)*ilData.rowInterval)+1);
			}
		} 
		return nextRowWrite;
	}

	/*******************************************************************
	 * METHOD: getNextColWrite
	 *
	 * A helper method calculating the next column to write when beginning
	 * a new tile.  This is only used when an interval is being used
	 * for thumbnail, summary, and ribbon vertical layer views.
	 ******************************************************************/
	private static int getNextColWrite(ImportLayerData ilData, int colStart) {	
		int nextColWrite = colStart;
		if (Arrays.asList(LAYER_THUMBNAIL, LAYER_SUMMARY, LAYER_RIBBONVERT).contains(ilData.layer)) {
			if ((colStart != 1) && (ilData.colInterval != 1)) {
				nextColWrite = (((colStart/ilData.colInterval)*ilData.colInterval)+1);
			}
		} 
		return nextColWrite;
	}
	
	/*******************************************************************
	 * METHOD: getInputFileRowCols
	 *
	 * This method reads the incoming matrix and extracts the number of
	 * data rows and columns.
	 ******************************************************************/
	private static int[] getInputFileRowCols(String[] fileInputs) {
		int rowId = 0;
		int[] rowCols = new int[2];
		BufferedReader br = null;
	    try {
			br = new BufferedReader(new FileReader(new File(fileInputs[0] + fileInputs[1])));
		    String sCurrentLine;
			while((sCurrentLine = br.readLine()) != null) {
				rowId++;
				if (rowId == 2) {
					String vals[] = sCurrentLine.split("\t");
					rowCols[1] = vals.length - 1;

				}
			}	
		    br.close();
		    // Set number of rows (accounting for header)
		    rowCols[0] = rowId - 1;
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    		br.close();
	    	} catch (Exception ex) {}
	    }
		return rowCols;
	}	
	
	/*******************************************************************
	 * METHOD: writeTileStructFile
	 *
	 * This method writes out the tilestructure.json file for the 
	 * generated heatmap. A thumb will always be written.  The levels 
	 * below will be written to the file if they are generated.
	 ******************************************************************/
	private static void writeTileStructFile(ImportData iData) {	
		DataOutputStream writeRow = null;
		OutputStreamWriter w = null;
		try {
			writeRow = new DataOutputStream(new FileOutputStream(iData.importDir + TILE_STRUCT_FILE));
			w = new OutputStreamWriter(writeRow, UTF8);
			// Build String constants
			w.write(BRACE_OPEN+LINE_FEED+TAB+LEVELS_LABEL);
			w.write(LINE_FEED+TAB+BRACE_OPEN);
			// Loop thru import layers and write out structure data for each.
			for (int i=0; i < iData.importLayers.size(); i++) {
				ImportLayerData ilData = iData.importLayers.get(i);
				// Write out the Thumbnail file structure data.
				w.write(LINE_FEED+TAB+TAB+QUOTE+ilData.layer+QUOTE+COLON);
				w.write(LINE_FEED+TAB+TAB+BRACE_OPEN);
				w.write(LINE_FEED+TAB+TAB+TAB+TILEROWS_LABEL+ilData.rowTiles);
				w.write(COMMA+LINE_FEED+TAB+TAB+TAB+TILECOLS_LABEL+ilData.colTiles);
				w.write(COMMA+LINE_FEED+TAB+TAB+TAB+TILEROWSPER_LABEL+ilData.rowsPerTile);
				w.write(COMMA+LINE_FEED+TAB+TAB+TAB+TILECOLSPER_LABEL+ilData.colsPerTile);
				w.write(COMMA+LINE_FEED+TAB+TAB+TAB+TOTALROWS_LABEL+ilData.totalLevelRows);
				w.write(COMMA+LINE_FEED+TAB+TAB+TAB+TOTALCOLS_LABEL+ilData.totalLevelCols);
				w.write(LINE_FEED+TAB+TAB+BRACE_CLOSE);
				if (i < (iData.importLayers.size() - 1)) {
					w.write(COMMA);
				}
			}
			w.write(LINE_FEED+TAB+BRACE_CLOSE+LINE_FEED+BRACE_CLOSE);
			w.close();
			writeRow.close();
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    		w.close();
	    		writeRow.close();
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
	}

	/*******************************************************************
	 * METHOD: writeLabelsFile
	 *
	 * This method writes out the colLabels and rowLabels JSON files. A
	 * boolean is passed in to differentiate between the two during 
	 * processing.  The reOrgMatrix 2-D string array stored on the 
	 * ImportData object is iterated to retrieve values and write them
	 * out to the appropriate JSON file.
	 ******************************************************************/
	private static void writeLabelsFiles(String fileName, ImportData iData, boolean isRowFile) {	
		DataOutputStream writeRow = null;
		OutputStreamWriter w = null;
		try {
			writeRow = new DataOutputStream(new FileOutputStream(fileName));
			w = new OutputStreamWriter(writeRow, UTF8);
			// Build String constants
			w.write(BRACE_OPEN+LINE_FEED+TAB+QUOTE+"Labels"+QUOTE+SPACE+COLON+SPACE);
			w.write(LINE_FEED+TAB+BRACKET_OPEN+LINE_FEED);
			// Loop thru import layers and write out structure data for each.
			if (isRowFile) {
		        for (int row = 1; row < iData.importRows + 1; row++) {
		        	w.write(TAB+TAB+QUOTE+iData.reorgMatrix[row][0]+QUOTE);
					if (row < (iData.importRows)) {
						w.write(COMMA);
						w.write(LINE_FEED);
					}
		        }
			} else {
		        for (int col = 1; col < iData.importCols + 1; col++) {
		        	w.write(TAB+TAB+QUOTE+iData.reorgMatrix[0][col]+QUOTE);
					if (col < (iData.importCols)) {
						w.write(COMMA);
						w.write(LINE_FEED);
					}
		        }
			}
			w.write(LINE_FEED+TAB+BRACKET_CLOSE+LINE_FEED+BRACE_CLOSE);
			w.close();
			writeRow.close();
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    		w.close();
	    		writeRow.close();
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
	}
	
	/*******************************************************************
	 * METHOD: writeClusteredDebugFile
	 *
	 * This method is for debugging.  It writes out the clustered
	 * data matrix to a file called clustered.txt in the matrix data dir.
	 ******************************************************************/
	private static void writeClusteredDebugFile(ImportData iData) {	
		DataOutputStream writeRow = null;
		OutputStreamWriter w = null;
		try {
			writeRow = new DataOutputStream(new FileOutputStream(iData.importDir + "clustered.txt"));
			w = new OutputStreamWriter(writeRow, UTF8);
	        for (int row = 1; row < iData.importRows + 1; row++) {
		        for (int col = 1; col < iData.importCols + 1; col++) {
		        	w.write(iData.reorgMatrix[row][col]);
					if (col < (iData.importCols)) {
						w.write(TAB);
					} else {
						w.write(LINE_FEED);
					}
		        }
	        }
			w.close();
			writeRow.close();
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    		w.close();
	    		writeRow.close();
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
	}
	
	/*******************************************************************
	 * METHOD: writeDendrogramFile
	 *
	 * This method writes out the dendrogram JSON  file. A FileWriter is 
	 * created for the dendro file and the populateDendrogramFile method 
	 * is called twice (once for the row and once for the column) to fill 
	 * in the dendro file.
	 ******************************************************************/
	private static void writeDendrogramFile(ImportData iData, int interval) {
		try {
			DataOutputStream writer = new DataOutputStream(new FileOutputStream(iData.importDir+DENDROGRAM_FILE));
			OutputStreamWriter fw = new OutputStreamWriter(writer, UTF8);
	        fw.write(BRACE_OPEN+LINE_FEED);
	        populateDendrogramFile(iData, iData.rowOrder, ROW, fw, interval);
	        fw.write(BRACKET_CLOSE+COMMA+LINE_FEED);
	        populateDendrogramFile(iData, iData.colOrder, COL, fw, interval);
            fw.write(BRACKET_CLOSE+LINE_FEED+BRACE_CLOSE);
	        fw.close();
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
	}
		
	/*******************************************************************
	 * METHOD: populateDendrogramFile
	 *
	 * This method writes out the dendrogram JSON  file. A string is passed 
	 * in to differentiate row/col during processing. The method uses 
	 * Row/Column HCORDER file to re-order the data located in the Row/Column 
	 * HCDATA file and writes the  result out as a JSON file. 
	 ******************************************************************/
	private static void populateDendrogramFile(ImportData iData, int[] order, String dendroType, OutputStreamWriter fw, int interval) {
        try {
            String DataFile = iData.importDir+dendroType+HCDATA_FILE;

            // Reading the data file and writing the output file
            BufferedReader br = new BufferedReader(new FileReader(DataFile));
            String line = br.readLine(); // skip the first line since it's just labels
            line = br.readLine();
            boolean firstTimeThrough = true;
            fw.write(QUOTE+"interval"+QUOTE+SPACE+COLON+SPACE+interval+COMMA+LINE_FEED);
            fw.write(QUOTE+dendroType+QUOTE+SPACE+COLON+LINE_FEED+TAB+BRACKET_OPEN);
            while (line != null) {
                String[] tokes = line.split(TAB);
                int a = Integer.parseInt(tokes[0]);
                int b = Integer.parseInt(tokes[1]);
                if (a<0){ // Check if first column is referring to a sample
                    a = 0-order[0-a];
                }
                if (b<0){ // Check if second column is referring to a sample
                    b = 0-order[0-b];
                }
                if (firstTimeThrough){
                    firstTimeThrough = false;
                } else {
                    fw.write(COMMA+LINE_FEED+TAB);
                }
                fw.write(QUOTE+ a +COMMA+ b +COMMA+ tokes[2] + QUOTE);
                line = br.readLine();
            }
            br.close();
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
	}
	
	/*******************************************************************
	 * METHOD: writeClassificationsFile
	 *
	 * This method writes out the classifications JSON file. An output stream
	 * is created for writing out the classifications.JSON file. The list of 
	 * classification files, stored on the ImportData object, is iterated for 
	 * each file.  The reOrderClassificationFile method is called to 
	 * order each classification file in clustered order. Then the 
	 * populateClassifications is called to write rows to the output file.
	 ******************************************************************/
	private static void writeClassificationsFile(ImportData iData, int interval) {
		try {
			DataOutputStream writer = new DataOutputStream(new FileOutputStream(iData.importDir+CLASSIFICATIONS_FILE));
			OutputStreamWriter fw = new OutputStreamWriter(writer, UTF8);
	        fw.write(BRACE_OPEN+LINE_FEED+TAB);
	        for (int i=0;i<iData.colClassFiles.length;i++) {
		        File currColFile = iData.colClassFiles[i];
	        	String reOrgClass[][] = reOrderClassificationFile(currColFile, iData.colOrder);
		        populateClassificationsFile(currColFile, reOrgClass, "column", i+1, fw, interval);
	        	if ((i != iData.colClassFiles.length - 1) || (iData.rowClassFiles.length > 0)) {
	        		fw.write(TAB+BRACE_CLOSE+COMMA+LINE_FEED+TAB);
	        	}
	        }
	        for (int i=0;i<iData.rowClassFiles.length;i++) {
		        File currRowFile = iData.rowClassFiles[i];
	        	String reOrgClass[][] = reOrderClassificationFile(currRowFile, iData.rowOrder);
	        	populateClassificationsFile(currRowFile, reOrgClass, "row", i+1, fw, interval);
	        }
            fw.write(TAB+BRACE_CLOSE+LINE_FEED+BRACE_CLOSE);
	        fw.close();
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
	}

	/*******************************************************************
	 * METHOD: reOrderClassificationFile
	 *
	 * This method re-orders a classification file in clustered order.
	 ******************************************************************/
	private static String[][] reOrderClassificationFile(File classFile, int[] order) {
		String reorg[][] = new String[order.length][2];
		try {
            // Reading the data file and writing the output file
            BufferedReader br = new BufferedReader(new FileReader(classFile));
            String line = br.readLine(); // skip header row
        //    line = br.readLine(); 
	        String origClass[][] = new String[order.length][2];
	        int pos = 0;
	        while(line !=null) {
	              String toks[] = line.split("\t");
	              for (int i = 0; i < toks.length; i++) {
	            	  origClass[pos][i] = toks[i];
	              }      
	              pos++;
	              line = br.readLine();
	        }
            br.close();
            
            //TEMPORARY: This saves off the discrete/continuous label that is temporarily on the classification file as the first row.
            //REVISIT: After we start getting CHM.JSON file containing this information.
            reorg[0][0] = origClass[0][0];
            
	        // Create a new 2D string array and populate it with data from the 
	        // initial 2D array placing it in the clustered order.
	        for (int row = 1; row < order.length; row++) {
	              reorg[order[row]] = origClass[row];
	        }
	        
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
		return reorg;
	}
	
	/*******************************************************************
	 * METHOD: populateClassificationsFile
	 *
	 * This method writes rows into the classifications.JSON file for 
	 * a given input classification file.
	 * 
	 * NOTE: Class File type and colorscheme are currently derived from
	 * the file name and a temporary header row on the classification file
	 * these will eventually come from a CHM.JSON file created by the 
	 * builder.
	 ******************************************************************/
	private static void populateClassificationsFile(File currFile, String classData[][], String classType, int classNo, OutputStreamWriter fw, int interval) {
        try {
        	String className = currFile.getName().substring(0,currFile.getName().indexOf("_"));
        	String colclass;
        	if (classType.equals("row")) { 
        		colclass = "RowClass"+classNo; 
			} else { 
				colclass = "ColClass"+classNo; 
			}        
	        fw.write(QUOTE+className+QUOTE+COLON+LINE_FEED+TAB+BRACE_OPEN+LINE_FEED);
	        fw.write(TAB+TAB+QUOTE+"position"+QUOTE+COLON+QUOTE+classType+QUOTE+COMMA+LINE_FEED);
	        fw.write(TAB+TAB+QUOTE+"height"+QUOTE+COLON+"15"+COMMA+LINE_FEED);
	        //TEMPORARY: Pulling discrete/continuous from first line of file.  This will come from CHM.JSON later
	        fw.write(TAB+TAB+QUOTE+"type"+QUOTE+COLON+QUOTE+classData[0][0]+QUOTE+COMMA+LINE_FEED);
	        fw.write(TAB+TAB+QUOTE+"colorScheme"+QUOTE+COLON+QUOTE+colclass+QUOTE+COMMA+LINE_FEED);
	        fw.write(TAB+TAB+QUOTE+"values"+QUOTE+COLON+LINE_FEED+TAB+TAB+BRACKET_OPEN+LINE_FEED);
	        // Write out a separate "values" node containing values for the classification file
	        for (int row = 1; row < classData.length; row++) {
	        	writeClassValue(classData[row][1], row, classData.length - 1, fw);
	        }
	        // Write out a separate "svalues" node containing values for the classification file
	        // this dataset will be sampled at the same level as the summary layer.
	        if (interval > 1) {
		        fw.write(COMMA+LINE_FEED+TAB+TAB+QUOTE+"svalues"+QUOTE+COLON+LINE_FEED+TAB+TAB+BRACKET_OPEN+LINE_FEED);
		        for (int row = 1; row < classData.length; row++) {
		        	int adjustedPos = row - 1;
		    		float remainder = ((float)adjustedPos/interval)%1;
		    		if (remainder == 0) {
			        	writeClassValue(classData[row][1], row, classData.length - 1, fw);
		    		}
		        }
	        } 
        	fw.write(LINE_FEED);
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
	}
	private static void writeClassValue(String val, int row, int len, OutputStreamWriter fw) {
        try {
        	if (isNumeric(val)) {
        		fw.write(TAB+TAB+val);
        	} else {
        		fw.write(TAB+TAB+QUOTE+val+QUOTE);
        	}
        	if (row != len) {
        		fw.write(COMMA+LINE_FEED);
        	} else {
        		fw.write(BRACKET_CLOSE);
        	}
	    } catch (Exception ex) {
	    	System.out.println("Exception: "+ ex.toString());
	    } finally {
	    	try {
	    	} catch (Exception ex) { /* Do nothing FOR NOW */ }
	    }
	}
}
